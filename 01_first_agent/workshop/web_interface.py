# web_interface.py
import streamlit as st
import asyncio
import logging
from strands import Agent
from strands.models import BedrockModel
from strands_tools import current_time, http_request



logging.basicConfig(
    level=logging.INFO,
    format="%(levelname)s | %(name)s | %(message)s",
    handlers=[logging.StreamHandler()]
)
logging.getLogger("strands").setLevel(logging.DEBUG)

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="Strands Agents å°åŠ©æ‰‹",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .tool-call-box {
        background-color: #f0f2f6;
        padding: 10px;
        border-radius: 5px;
        margin-bottom: 10px;
    }
    .tool-name {
        font-weight: bold;
        color: #0068c9;
    }
    .tool-params {
        font-family: monospace;
        background-color: #f8f9fa;
        padding: 5px;
        border-radius: 3px;
    }
</style>
""", unsafe_allow_html=True)

# å¯ç”¨çš„æ¨¡å‹é…ç½®
MODELS = {
    "Amazon Nova Pro": "amazon.nova-pro-v1:0",
    "Amazon Nova Rremier": "us.amazon.nova-premier-v1:0",
    "Claude 3.7 Sonnet": "us.anthropic.claude-3-7-sonnet-20250219-v1:0"
}

# åˆå§‹åŒ–Agent
def init_agent(model_id=None):
    # å¦‚æœæŒ‡å®šäº†æ¨¡å‹IDï¼Œä½¿ç”¨Bedrockæ¨¡å‹
    if model_id:
        model = BedrockModel(model_id=model_id)
        return Agent(
            system_prompt="""ä½ æ˜¯ä¸€ä¸ªä¸­å›½å›½å†…çš„ç”Ÿæ´»åŠ©æ‰‹ï¼Œè¿ç”¨ç§‘å­¦çš„çŸ¥è¯†å›ç­”å„ç§é—®é¢˜ã€‚
            è¯·ä½¿ç”¨toolæ¥å›ç­”é—®é¢˜ï¼Œå¦‚æœç”¨æˆ·é—®é—®é¢˜ï¼Œè¯·ç”¨http_requestå·¥å…·ï¼ŒæŸ¥è¯¢ä¸­å›½å›½å†…çš„ç™¾ç§‘ç½‘ç«™ã€‚
            """,
            model=model,
            tools=[current_time, http_request],
            callback_handler=None  # ç¦ç”¨å›è°ƒå¤„ç†å™¨ï¼Œä½¿ç”¨æµå¼è¾“å‡º
        )
    else:
        # é»˜è®¤ä½¿ç”¨ç³»ç»Ÿé…ç½®çš„æ¨¡å‹
        return Agent(
            system_prompt="""
            You are a lifestyle assistant for users in mainland China, 
            proficient in scientific knowledge and capable of addressing various everyday questions. 
            When users ask questions, prioritize using the http_request tool to query  Chinese websites (such as Baidu Baike, China Science Communication Network, etc.) to obtain the most current and accurate information. 
            Your responses should be based on scientific facts, concise, and appropriate for Chinese cultural context. 
            When encountering uncertain information, clearly inform the user and provide reliable information that is known.
            """,
            tools=[current_time, http_request],
            callback_handler=None  # ç¦ç”¨å›è°ƒå¤„ç†å™¨ï¼Œä½¿ç”¨æµå¼è¾“å‡º
        )

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "messages" not in st.session_state:
    st.session_state.messages = []

if "selected_model" not in st.session_state:
    st.session_state.selected_model = "Amazon Nova Pro"  # é»˜è®¤é€‰æ‹©

if "agent" not in st.session_state:
    model_id = MODELS[st.session_state.selected_model]
    st.session_state.agent = init_agent(model_id)

async def process_user_input_streaming(prompt):
    """ä½¿ç”¨å¼‚æ­¥æµå¼å¤„ç†ç”¨æˆ·è¾“å…¥"""
    try:
        # ä½¿ç”¨å¼‚æ­¥æµå¼è¾“å‡º
        full_response = ""
        async for event in st.session_state.agent.stream_async(prompt):
            if "data" in event:
                # ç´¯ç§¯æ–‡æœ¬
                full_response += event["data"]
        
        # è¿”å›å®Œæ•´å“åº”
        return full_response
        
    except Exception as e:
        return f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°äº†é”™è¯¯ï¼š{str(e)}"

def process_user_input(prompt):
    """å¤„ç†ç”¨æˆ·è¾“å…¥ï¼ˆç”¨äºç¤ºä¾‹æŒ‰é’®ï¼‰"""
    try:
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        logging.info("prompt æ˜¯ï¼š" +prompt) 
        response = st.session_state.agent(prompt)

        # æ·»åŠ AIå›å¤åˆ°å†å²
        st.session_state.messages.append({"role": "assistant", "content": response})
        
        return True
        
    except Exception as e:
        error_msg = f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°äº†é”™è¯¯ï¼š{str(e)}"
        st.session_state.messages.append({"role": "assistant", "content": error_msg})
        return False

def main():
    st.title("Strands AIåŠ©æ‰‹")
    st.markdown("---")
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.header("åŠŸèƒ½ä»‹ç»")
        st.markdown("""
        **AIåŠ©æ‰‹åŠŸèƒ½ï¼š**
        - è·å–å½“å‰æ—¶é—´
        - ç½‘ç»œä¿¡æ¯æœç´¢
        - çŸ¥è¯†é—®ç­”
        - ç”Ÿæ´»å»ºè®®
        
        **ä½¿ç”¨æ–¹æ³•ï¼š**
        åœ¨ä¸‹æ–¹è¾“å…¥æ¡†ä¸­è¾“å…¥æ‚¨çš„é—®é¢˜ï¼ŒAIåŠ©æ‰‹å°†ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚
        """)
        
        # ç¤ºä¾‹é—®é¢˜æ”¾åœ¨ä¾§è¾¹æ ï¼ˆåªå±•ç¤ºï¼Œä¸èƒ½ç‚¹å‡»ï¼‰
        st.markdown("---")
        st.markdown("**è¯•è¯•è¿™äº›é—®é¢˜ï¼š**")
        
        # ä½¿ç”¨æ™®é€šæ–‡æœ¬æ˜¾ç¤ºç¤ºä¾‹é—®é¢˜ï¼Œç¡®ä¿æ¯ä¸ªé—®é¢˜å•ç‹¬ä¸€è¡Œ
        st.markdown("â€¢ ç°åœ¨å‡ ç‚¹äº†ï¼Ÿ")
        st.markdown("â€¢ å¸®æˆ‘æŸ¥è¯¢ä¸€ä¸‹åŒ—äº¬ä»Šå¤©çš„å¤©æ°”æƒ…å†µ")
        st.markdown("â€¢ ä»€ä¹ˆæ˜¯æ¢…é›¨ï¼Ÿè¯·è¯¦ç»†è§£é‡Šä¸€ä¸‹")
        
        # æ·»åŠ æç¤º
        st.caption("åœ¨è¾“å…¥æ¡†ä¸­è¾“å…¥ä¸Šè¿°é—®é¢˜æ¥è·å–å›ç­”")
        
        st.markdown("---")
        
        # æ¨¡å‹é€‰æ‹©ä¸‹æ‹‰æ¡†
        st.subheader("æ¨¡å‹é€‰æ‹©")
        selected_model = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            options=list(MODELS.keys()),
            index=list(MODELS.keys()).index(st.session_state.selected_model)
        )
        
        # å¦‚æœæ¨¡å‹é€‰æ‹©æ”¹å˜ï¼Œé‡æ–°åˆå§‹åŒ–Agent
        if selected_model != st.session_state.selected_model:
            st.session_state.selected_model = selected_model
            model_id = MODELS[selected_model]
            st.session_state.agent = init_agent(model_id)
            st.success(f"å·²åˆ‡æ¢åˆ° {selected_model} æ¨¡å‹")
        
        st.markdown("---")
        if st.button("æ¸…ç©ºå¯¹è¯å†å²"):
            st.session_state.messages = []
            st.rerun()
    
    # æ˜¾ç¤ºå¯¹è¯å†å²
    st.subheader("å¯¹è¯åŒºåŸŸ")
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# è¾“å…¥æ¡†å¤„ç†
def render_chat_input():
    """æ¸²æŸ“èŠå¤©è¾“å…¥æ¡†"""
    if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
        # å…ˆæ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
        col1, col2 = st.columns([3, 1])
        
        # åˆ›å»ºAIå›å¤çš„å ä½ç¬¦
        with col1, st.chat_message("assistant"):
            message_placeholder = st.empty()
            
            # åˆ›å»ºå·¥å…·è°ƒç”¨æ˜¾ç¤ºåŒºåŸŸ
            with col2:
                tool_placeholder = st.empty()
                tool_calls = []
            
            # å¼‚æ­¥è·å–æµå¼å“åº”
            async def get_streaming_response():
                full_response = ""
                try:
                    async for event in st.session_state.agent.stream_async(prompt):
                        # å¤„ç†æ–‡æœ¬äº‹ä»¶
                        if "data" in event:
                            full_response += event["data"]
                            message_placeholder.markdown(full_response + "â–Œ")
                        
                        # å¤„ç†å·¥å…·è°ƒç”¨äº‹ä»¶
                        if "current_tool_use" in event:
                            tool_info = event["current_tool_use"]
                            tool_name = tool_info.get("name", "æœªçŸ¥å·¥å…·")
                            tool_input = tool_info.get("input", {})
                            
                            # è®°å½•å·¥å…·è°ƒç”¨
                            if tool_name not in [t["name"] for t in tool_calls]:
                                tool_calls.append({
                                    "name": tool_name,
                                    "input": tool_input
                                })
                            
                            # æ›´æ–°å·¥å…·è°ƒç”¨æ˜¾ç¤º
                            tool_html = "<div style='background-color:#f0f2f6;padding:10px;border-radius:5px;'>"
                            tool_html += "<h4>å·¥å…·è°ƒç”¨:</h4>"
                            for i, tool in enumerate(tool_calls):
                                tool_html += f"<p><b>{i+1}. {tool['name']}</b></p>"
                            tool_html += "</div>"
                            tool_placeholder.markdown(tool_html, unsafe_allow_html=True)
                    
                    # ç§»é™¤å…‰æ ‡
                    message_placeholder.markdown(full_response)
                    return full_response
                except Exception as e:
                    error_msg = f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°äº†é”™è¯¯ï¼š{str(e)}"
                    message_placeholder.markdown(error_msg)
                    return error_msg
            
            # è¿è¡Œå¼‚æ­¥å‡½æ•°å¹¶è·å–ç»“æœ
            response = asyncio.run(get_streaming_response())
            
            # æ·»åŠ AIå›å¤åˆ°å†å²
            st.session_state.messages.append({"role": "assistant", "content": response})

if __name__ == "__main__":
    main()
    render_chat_input()